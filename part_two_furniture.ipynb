{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8eFW_wl1n39",
        "outputId": "6f3f2a7b-c81e-486a-b8b9-1ed018c0ba8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 114 kB in 2s (68.1 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Activate Spark in our Colab notebook.\n",
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.2.2'\n",
        "spark_version = 'spark-3.2.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCrgs0Z1rnw",
        "outputId": "f1fe53de-50d1-45ed-ce95-00e3c040abe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 00:47:19--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.1’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-03-21 00:47:19 (10.8 MB/s) - ‘postgresql-42.2.9.jar.1’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get postgresql package\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0DuBth0V2PR8"
      },
      "outputs": [],
      "source": [
        "# Import Spark and create a SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BigData-HW-1\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3W2XJVi2CU-"
      },
      "source": [
        "# Extract the Amazon Data into Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_stw7b1wfU",
        "outputId": "3fb536da-03b8-4d37-f476-12ddc03a5454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   24509695|R3VR960AHLFKDV|B004HB5E0E|     488241329|Shoal Creek Compu...|       Furniture|          4|            0|          0|   N|                Y|... desk is very ...|This desk is very...| 2015-08-31|\n",
            "|         US|   34731776|R16LGVMFKIUT0G|B0042TNMMS|     205864445|Dorel Home Produc...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|          Great item| 2015-08-31|\n",
            "|         US|    1272331|R1AIMEEPYHMOE4|B0030MPBZ4|     124663823|Bathroom Vanity T...|       Furniture|          5|            1|          1|   N|                Y|          Five Stars|Perfect fit for m...| 2015-08-31|\n",
            "|         US|   45284262|R1892CCSZWZ9SR|B005G02ESA|     382367578|Sleep Master Ulti...|       Furniture|          3|            0|          0|   N|                Y|         Good enough|We use this on a ...| 2015-08-31|\n",
            "|         US|   30003523|R285P679YWVKD1|B005JS8AUA|     309497463|1 1/4\" GashGuards...|       Furniture|          3|            0|          0|   N|                N|Gash Gards for da...|The product is fi...| 2015-08-31|\n",
            "|         US|   18311821| RLB33HJBXHZHU|B00AVUQQGQ|     574537906|Serta Bonded Leat...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|Love this product...| 2015-08-31|\n",
            "|         US|   42943632|R1VGTZ94DBAD6A|B00CFY20GQ|     407473883|Prepac Shoe Stora...|       Furniture|          5|            2|          2|   N|                Y|   I love this bench|I love this bench...| 2015-08-31|\n",
            "|         US|   43157304|R168KF82ICSOHD|B00FKC48QA|     435120460|HomCom PU Leather...|       Furniture|          5|            0|          0|   N|                Y|Great storage cap...|Have had this for...| 2015-08-31|\n",
            "|         US|   51918480|R20DIYIJ0OCMOG|B00N9IAL9K|     356495985|  Folding Step Stool|       Furniture|          5|            0|          0|   N|                Y|This is the best ...|This is the best ...| 2015-08-31|\n",
            "|         US|   14522766| RD46RNVOHNZSC|B001T4XU1C|     243050228|Ace Bayou Adult V...|       Furniture|          5|            0|          0|   N|                Y|    great for price!|    my son loves it!| 2015-08-31|\n",
            "|         US|   43054112|R2JDOCETTM3AXS|B002HRFLBC|      93574483|4D Concepts Audio...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|       Great product| 2015-08-31|\n",
            "|         US|   26622950|R33YMW36IDZ6LE|B006MISZOC|     941823468|Zinus SC-SBBK-14N...|       Furniture|          5|            0|          0|   N|                Y|             perfect|bought with sleep...| 2015-08-31|\n",
            "|         US|   17988940|R30ZGGUHZ04C1S|B008BMGABC|     460567746|Poundex Marble Di...|       Furniture|          5|            1|          1|   N|                Y|   Very satisfied!!!|Delivery was on t...| 2015-08-31|\n",
            "|         US|   18444952| RS2EZU76IK2BT|B00CO2VH5Y|     829613894|Safavieh Lyndhurs...|       Furniture|          5|            0|          0|   N|                Y|soft and great fo...|Exactly as pictur...| 2015-08-31|\n",
            "|         US|   16937084|R1GJC1BP028XO9|B00LI4RJQ0|     816478187|Sauder Boone Moun...|       Furniture|          5|            2|          3|   N|                Y|        Great table.|Beautiful table. ...| 2015-08-31|\n",
            "|         US|   23665632|R2VKJPGXXEK5GP|B0046EC1D0|     358594389|Winsome Wood Brea...|       Furniture|          1|            0|          0|   N|                Y|Not what I expect...|I have cleaned up...| 2015-08-31|\n",
            "|         US|    4110125|R17KS83G3KLT97|B00DQQPL36|     312571325|HODEDAH IMPORT Me...|       Furniture|          3|            0|          0|   N|                Y|         Three Stars|First one came in...| 2015-08-31|\n",
            "|         US|     107621|R3PQL8SR4NEHWL|B003X7RWB2|     402665054|Flash Furniture H...|       Furniture|          4|            0|          0|   N|                Y|          Four Stars|Good deal to get ...| 2015-08-31|\n",
            "|         US|    2415090|R2F5WW7WNO5RRG|B001TJYPJ8|     854989315|Sleep Revolution ...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|Comfortable and e...| 2015-08-31|\n",
            "|         US|   48285966|R3UDJKVWQCFIC9|B000TMHX9A|     814079288|Flash Furniture V...|       Furniture|          5|            0|          0|   N|                Y|Very comfortable....|As advertised. Ve...| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in the data from an S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz\"\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "furniture_df = spark.read.csv(SparkFiles.get(\"amazon_reviews_us_Furniture_v1_00.tsv.gz\"), sep=\"\\t\", header=True, ignoreLeadingWhiteSpace=True)\n",
        "\n",
        "# Show DataFrame\n",
        "furniture_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cayz-3Q52IM3",
        "outputId": "2e58d6ab-ab84-4557-e12b-7eeab4d69b1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "792113"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Get the number of rows in the DataFrame.\n",
        "row = furniture_df.count()\n",
        "row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9U0rkGZ2eu7"
      },
      "source": [
        "# Transform the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"review_id_table\"."
      ],
      "metadata": {
        "id": "dUoftWoKtM_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tMYkSIk2d-m",
        "outputId": "a01a4c38-b3fe-49d5-deeb-0a4544d8a073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|     review_id|customer_id|product_id|product_parent|review_date|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|R3VR960AHLFKDV|   24509695|B004HB5E0E|     488241329| 2015-08-31|\n",
            "|R16LGVMFKIUT0G|   34731776|B0042TNMMS|     205864445| 2015-08-31|\n",
            "|R1AIMEEPYHMOE4|    1272331|B0030MPBZ4|     124663823| 2015-08-31|\n",
            "|R1892CCSZWZ9SR|   45284262|B005G02ESA|     382367578| 2015-08-31|\n",
            "|R285P679YWVKD1|   30003523|B005JS8AUA|     309497463| 2015-08-31|\n",
            "| RLB33HJBXHZHU|   18311821|B00AVUQQGQ|     574537906| 2015-08-31|\n",
            "|R1VGTZ94DBAD6A|   42943632|B00CFY20GQ|     407473883| 2015-08-31|\n",
            "|R168KF82ICSOHD|   43157304|B00FKC48QA|     435120460| 2015-08-31|\n",
            "|R20DIYIJ0OCMOG|   51918480|B00N9IAL9K|     356495985| 2015-08-31|\n",
            "| RD46RNVOHNZSC|   14522766|B001T4XU1C|     243050228| 2015-08-31|\n",
            "|R2JDOCETTM3AXS|   43054112|B002HRFLBC|      93574483| 2015-08-31|\n",
            "|R33YMW36IDZ6LE|   26622950|B006MISZOC|     941823468| 2015-08-31|\n",
            "|R30ZGGUHZ04C1S|   17988940|B008BMGABC|     460567746| 2015-08-31|\n",
            "| RS2EZU76IK2BT|   18444952|B00CO2VH5Y|     829613894| 2015-08-31|\n",
            "|R1GJC1BP028XO9|   16937084|B00LI4RJQ0|     816478187| 2015-08-31|\n",
            "|R2VKJPGXXEK5GP|   23665632|B0046EC1D0|     358594389| 2015-08-31|\n",
            "|R17KS83G3KLT97|    4110125|B00DQQPL36|     312571325| 2015-08-31|\n",
            "|R3PQL8SR4NEHWL|     107621|B003X7RWB2|     402665054| 2015-08-31|\n",
            "|R2F5WW7WNO5RRG|    2415090|B001TJYPJ8|     854989315| 2015-08-31|\n",
            "|R3UDJKVWQCFIC9|   48285966|B000TMHX9A|     814079288| 2015-08-31|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\n",
        "review_id_df = furniture_df.select([\"review_id\", \"customer_id\",\"product_id\", \"product_parent\", \"review_date\"])\n",
        "review_id_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"products\" Table"
      ],
      "metadata": {
        "id": "aAVCFjXhtXO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "g9gTNhT62je4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0945379b-17f8-4b79-9fe6-a089f80d3b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|product_id|       product_title|\n",
            "+----------+--------------------+\n",
            "|B0049H81OM|Fun Rugs Surf Tim...|\n",
            "|B001U0UOO6|Furniture Repair Set|\n",
            "|B0076I51JE|Traditional Opera...|\n",
            "|B007OWPBGU|Frenchi Home Furn...|\n",
            "|B00DHWGB4M|Circle Design Sid...|\n",
            "|B00RI6TNJ8|Abrahami Hariz Bu...|\n",
            "|B00GHZA29Q|nuLOOM Varanas Co...|\n",
            "|B00GSIIGQS|Milton Greens Sta...|\n",
            "|B00VZ4RY1I|Dean Shifting San...|\n",
            "|B007QUM5DM| Charles Petite Sofa|\n",
            "|B00MN6NTDO|Safavieh Adironda...|\n",
            "|B00BK31LDQ|Glass Computer De...|\n",
            "|B0091SXURW|Altra Parsons Des...|\n",
            "|B00TBVK0Y0|Best Price Mattre...|\n",
            "|B00A2XM5QC|Legacy Decor Shoj...|\n",
            "|B002KE7HTQ|Home Styles 5001-...|\n",
            "|B00V3LVD2O|Roundhill Furnitu...|\n",
            "|B00PN9YSAG|Baxton Studio Hir...|\n",
            "|B005VAFFN6|Duro Hanley Silve...|\n",
            "|B001BX1JSC|Flash Furniture V...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \n",
        "products_df = furniture_df.select([\"product_id\", \"product_title\"])\n",
        "products_df = products_df.dropDuplicates()\n",
        "products_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"customers\" Table"
      ],
      "metadata": {
        "id": "LJHuZ9zut0e5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pF2Vf3c2n2O",
        "outputId": "22b3ec4a-bffd-437c-872c-d093b48ee695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|customer_count|\n",
            "+-----------+--------------+\n",
            "|   46447787|             2|\n",
            "|   28029004|             3|\n",
            "|   50583551|             2|\n",
            "|   10624936|             1|\n",
            "|   30238476|             1|\n",
            "|   20228001|             1|\n",
            "|   27199526|             1|\n",
            "|   13866959|             1|\n",
            "|   50073543|             1|\n",
            "|   10413211|             1|\n",
            "|   18895714|             1|\n",
            "|   47104694|             1|\n",
            "|   36135761|             1|\n",
            "|    1051766|             1|\n",
            "|   26246534|             1|\n",
            "|    1713089|             1|\n",
            "|    1446645|             1|\n",
            "|   52809622|             6|\n",
            "|   10820329|             1|\n",
            "|   26614679|             2|\n",
            "+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \n",
        "customers_df = furniture_df.groupBy([\"customer_id\"]).count()\n",
        "customers_df = customers_df.withColumnRenamed(\"count\", \"customer_count\")\n",
        "customers_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"vine_table\"."
      ],
      "metadata": {
        "id": "8SbTasxbuXGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQKbmCE2p3Q",
        "outputId": "71e450f0-b33e-4e92-b7ad-5f406b019d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R3VR960AHLFKDV|          4|            0|          0|   N|\n",
            "|R16LGVMFKIUT0G|          5|            0|          0|   N|\n",
            "|R1AIMEEPYHMOE4|          5|            1|          1|   N|\n",
            "|R1892CCSZWZ9SR|          3|            0|          0|   N|\n",
            "|R285P679YWVKD1|          3|            0|          0|   N|\n",
            "| RLB33HJBXHZHU|          5|            0|          0|   N|\n",
            "|R1VGTZ94DBAD6A|          5|            2|          2|   N|\n",
            "|R168KF82ICSOHD|          5|            0|          0|   N|\n",
            "|R20DIYIJ0OCMOG|          5|            0|          0|   N|\n",
            "| RD46RNVOHNZSC|          5|            0|          0|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \n",
        "vine_df = furniture_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\",  \"vine\"])\n",
        "vine_df.show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8aTsEjZ2s6L"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "W4dzUKfI2vXM"
      },
      "outputs": [],
      "source": [
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://<endpoint>:5432/kitchen_my_data_class_db\"\n",
        "config = {\"user\":\"postgres\", \"password\": \"postgres\", \"driver\":\"org.postgresql.Driver\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iOxKqMsD2yVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f78e166-7cfa-439d-87a5-962738b419d3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d23a50148781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write review_id_df to table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview_id_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'review_id_df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o145.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:292)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:211)\n\tat org.postgresql.Driver.makeConnection(Driver.java:458)\n\tat org.postgresql.Driver.connect(Driver.java:260)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.UnknownHostException: <endpoint>\n\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)\n\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.base/java.net.Socket.connect(Socket.java:609)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:75)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:91)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:192)\n\t... 50 more\n"
          ]
        }
      ],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "review_id_df.write.jdbc(url=jdbc_url, table='review_id_df', mode=mode, properties=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPXyGVE-2yPJ"
      },
      "outputs": [],
      "source": [
        "# Write products_df to table in RDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHbca4zN2yIa"
      },
      "outputs": [],
      "source": [
        "# Write customers_df to table in RDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HfOFneW2x_F"
      },
      "outputs": [],
      "source": [
        "# Write vine_df to table in RDS\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}